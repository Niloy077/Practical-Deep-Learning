{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b03c5b-1d95-44a3-b7db-03a2db592d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "096d7418-b40c-4d7a-a6a1-03b00143d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe1183e-dfce-4764-8984-a2e04363ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset (X = Inputs, Y = Labels)\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # XOR dataset\n",
    "Y = np.array([[0], [1], [1], [0]])  # Expected output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4055fe39-f9fd-46b1-b4c4-acc5e3ad6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)  # For reproducibility\n",
    "\n",
    "input_neurons = 2   # Number of input features\n",
    "hidden_neurons = 3  # Number of hidden layer neurons\n",
    "output_neurons = 1  # Number of output neurons\n",
    "\n",
    "# Weights and biases for input -> hidden\n",
    "W1 = np.random.randn(input_neurons, hidden_neurons)\n",
    "b1 = np.zeros((1, hidden_neurons))\n",
    "\n",
    "# Weights and biases for hidden -> output\n",
    "W2 = np.random.randn(hidden_neurons, output_neurons)\n",
    "b2 = np.zeros((1, output_neurons))\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cfcbade-7c7c-4f38-9e57-2b4d06b8de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions before training:\n",
      " [[0.5       ]\n",
      " [0.34101951]\n",
      " [0.94449498]\n",
      " [0.68329752]]\n"
     ]
    }
   ],
   "source": [
    "# Forward pass (Input to Hidden)\n",
    "Z1 = np.dot(X, W1) + b1\n",
    "A1 = relu(Z1)  # Activation function\n",
    "\n",
    "# Forward pass (Hidden to Output)\n",
    "Z2 = np.dot(A1, W2) + b2\n",
    "A2 = sigmoid(Z2)  # Output activation function\n",
    "\n",
    "print(\"Predictions before training:\\n\", A2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "742c92a9-bc44-4e4e-b948-6656f1061823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 0.7439650431610728\n"
     ]
    }
   ],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "# Compute loss\n",
    "initial_loss = loss(Y, A2)\n",
    "print(\"Initial Loss:\", initial_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ef8648-ca4f-4de0-bc7f-d883c6d9fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Gradients\n",
    "dL_dA2 = A2 - Y  # Gradient of loss w.r.t output\n",
    "dA2_dZ2 = sigmoid_derivative(A2)  # Derivative of sigmoid\n",
    "dZ2_dW2 = A1  # Input to output layer\n",
    "\n",
    "# Gradients for output layer\n",
    "dW2 = np.dot(dZ2_dW2.T, dL_dA2 * dA2_dZ2)\n",
    "db2 = np.sum(dL_dA2 * dA2_dZ2, axis=0, keepdims=True)\n",
    "\n",
    "# Gradients for hidden layer\n",
    "dA1_dZ1 = relu_derivative(Z1)\n",
    "dL_dZ1 = np.dot(dL_dA2 * dA2_dZ2, W2.T) * dA1_dZ1\n",
    "\n",
    "dW1 = np.dot(X.T, dL_dZ1)\n",
    "db1 = np.sum(dL_dZ1, axis=0, keepdims=True)\n",
    "\n",
    "# Update weights and biases\n",
    "W1 -= lr * dW1\n",
    "b1 -= lr * db1\n",
    "W2 -= lr * dW2\n",
    "b2 -= lr * db2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "799dc585-8656-479a-a7f0-6076a5eddbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.71895\n",
      "Epoch 1000, Loss: 0.07094\n",
      "Epoch 2000, Loss: 0.04137\n",
      "Epoch 3000, Loss: 0.03136\n",
      "Epoch 4000, Loss: 0.02606\n",
      "Epoch 5000, Loss: 0.02267\n",
      "Epoch 6000, Loss: 0.02029\n",
      "Epoch 7000, Loss: 0.01849\n",
      "Epoch 8000, Loss: 0.01709\n",
      "Epoch 9000, Loss: 0.01595\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Forward pass\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    # Compute Loss\n",
    "    loss_value = loss(Y, A2)\n",
    "\n",
    "    # Backpropagation\n",
    "    dL_dA2 = A2 - Y  # Gradient of loss w.r.t output\n",
    "    dA2_dZ2 = sigmoid_derivative(A2)  # Derivative of sigmoid\n",
    "    dZ2_dW2 = A1  # Input to output layer\n",
    "\n",
    "    # Gradients for output layer\n",
    "    dW2 = np.dot(dZ2_dW2.T, dL_dA2 * dA2_dZ2)\n",
    "    db2 = np.sum(dL_dA2 * dA2_dZ2, axis=0, keepdims=True)\n",
    "\n",
    "    # Gradients for hidden layer\n",
    "    dA1_dZ1 = relu_derivative(Z1)\n",
    "    dL_dZ1 = np.dot(dL_dA2 * dA2_dZ2, W2.T) * dA1_dZ1\n",
    "\n",
    "    dW1 = np.dot(X.T, dL_dZ1)\n",
    "    db1 = np.sum(dL_dZ1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update weights and biases\n",
    "    W1 -= lr * dW1\n",
    "    b1 -= lr * db1\n",
    "    W2 -= lr * dW2\n",
    "    b2 -= lr * db2\n",
    "\n",
    "    # Print loss every 1000 epochs\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Epoch {i}, Loss: {loss_value:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88280e29-8f02-4179-9f07-5c7678f18491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Predictions:\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Forward pass after training\n",
    "Z1 = np.dot(X, W1) + b1\n",
    "A1 = relu(Z1)\n",
    "Z2 = np.dot(A1, W2) + b2\n",
    "A2 = sigmoid(Z2)\n",
    "\n",
    "# Convert predictions to binary (0 or 1)\n",
    "predictions = (A2 > 0.5).astype(int)\n",
    "\n",
    "print(\"Final Predictions:\\n\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2bd772-7f0d-4f82-901e-0a266fd82062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
